# experiment_scripts/ties.py
# ==============================================================================
# Goal
# ----
# For a *single* “tie-like” image (ambiguous between two classes), plot the
# per-layer kernel mean embedding scores μ̂_{p_{t,y}}(z_t) against each of the
# two competing classes, using:
#   • Cosine kernel on unit-sphere features
#   • MK-RBF (multi-kernel RBF with per-layer sigma grids + optional PCA)
#
# Prereqs
# -------
# - A saved candidate image (e.g., generated by find_tie_like_candidates).
# - Optionally, cached [CLS] states for your class labels; this script computes
#   them on the fly for the two classes defined in `tie_pool`.
#
# Outputs
# -------
# - Two line plots (PDF) under plots/tie_trajectories/ showing μ̂ vs layer for:
#     1) cosine kernel
#     2) MK-RBF kernel
# - Printed cumulative differences for cosine and MK curves.
# ==============================================================================

import os
import numpy as np
from PIL import Image
from matplotlib import pyplot as plt

from src.ClsHiddenGeometry import ClsHiddenGeometry


# ------------------------------------------------------------------------------
# 1) Load a pretrained ImageNet-1k ViT and attach utilities for [CLS] geometry.
# ------------------------------------------------------------------------------
# Use "cuda:0" if you have a GPU; "mps" is great on Apple Silicon; "cpu" works anywhere.
m = ClsHiddenGeometry("google/vit-base-patch16-224", device="mps")

# Optional: automatically mine ambiguous (“tie-like”) candidates and save them.
# This can be slow; once you’ve generated JPEGs in plots/candidates_ties/, comment it back out.
# results = m.find_tie_like_candidates(print_top_k=5, max_candidates=1000)

# See the true label for a specific validation index.
# (This reads from the locally cached HF ImageNet-256 split, downloading if needed.)
idxs = [45365]
m.print_true_labels_for_val_indices(idxs)


# ------------------------------------------------------------------------------
# 2) Define the ambiguous pair (“tie pool”) and ILSVRC class names.
# ------------------------------------------------------------------------------
# The full strings here should match ImageNet’s class *names* exactly. We then
# provide shorter aliases in `abv_labels` and *rename* the cached entry via
# `merge_hidden_cls_states` (see next section).
tie_pool = [
    "cellular telephone, cellular phone, cellphone, cell, mobile phone",
    "mouse, computer mouse",
]
abv_labels = ["cellphone", "mouse"]  # shorter labels used for plotting
true_label = "cellphone"             # label used only to name output files

# Candidate JPEG produced by find_tie_like_candidates (update as needed).
img_path = "../plots/candidates_ties/947__idx0024373__Sm0.90__uni0.76__pm0.025__zm0.06.jpg"

# MK configuration: try PCA energy thresholds per layer and keep the best by bootstrap std-score.
thr_grid = [0.90, 0.95, 0.97, 0.99]

# Where to save figures produced below.
out_dir = "../plots/tie_trajectories"
os.makedirs(out_dir, exist_ok=True)  # ensure the output directory exists


# ------------------------------------------------------------------------------
# 3) Prepare class distributions p_{t,y}: compute & (re)label cached [CLS] states.
# ------------------------------------------------------------------------------
# We build p_{t,y} for each verbose ImageNet label, then “merge” each single entry
# to a new key with a shorter alias. (Merging one entry is effectively a rename;
# with delete_old=True it drops the original long-name key.)
for i in range(len(tie_pool)):
    m.compute_hidden_cls_states(tie_pool[i], num_samples=700, batch_size=100)
    m.merge_hidden_cls_states([(tie_pool[i], 700)], new_label=abv_labels[i])

# ------------------------------------------------------------------------------
# 4) Load the candidate image and set up consistent styling.
# ------------------------------------------------------------------------------
# If you get a FileNotFoundError, double-check `img_path` above.
img = Image.open(img_path).convert("RGB")

# Stable color assignment for the two classes across both plots
from matplotlib.colors import ListedColormap
idx = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 1]  # pick distinct hues from tab20
cmap = ListedColormap([plt.cm.tab20.colors[i] for i in idx])
colors = {lab: cmap(i % 11) for i, lab in enumerate(abv_labels)}

L = int(m.config.num_hidden_layers)   # e.g., 12 for ViT-Base
x = np.arange(1, L + 1)               # layers 1..L (human-friendly indexing)
cos = []
mk = []


# ------------------------------------------------------------------------------
# 5) μ̂ trajectories with the cosine kernel
# ------------------------------------------------------------------------------
# For each contender y ∈ {cellphone, mouse}, evaluate μ̂_{p_{t,y}}(z_t) along layers
# for the same image z, then plot both lines together.
plt.figure(figsize=(10, 6))
for y_label in abv_labels:
    vals, _ = m.mu_hat_along_layers(
        class_label=y_label,
        n_samples=700,       # must match the cache we built above
        image_z=img,
        true_label=true_label,   # only used to name files inside the method
        kernel="cosine",
        plot_res=False
    )
    # The legend includes the trajectory’s mean as a quick summary statistic.
    plt.plot(x, vals, marker="o", linewidth=2.8,
             label=f"{y_label} ({np.mean(vals):.2f})",
             color=colors[y_label])
    print(f"COS mu hat for test img {true_label}")
    cos.append(vals)

plt.legend(loc="best", fontsize=22, ncols=1)
plt.tick_params(axis='both', which='major', labelsize=16)
plt.tight_layout()
safe = true_label.replace("/", "__").replace(" ", "_")
plt.savefig(os.path.join(out_dir, f"{safe}__vs_all__cos.pdf"))
plt.close()

# Simple separability summary: accumulate |Δ| across layers between the two curves.
# (Higher cumulative difference means the kernels separate the two classes more.)
cos_diff = np.abs(cos[1] - cos[0])
cos_cum_diff = np.sum(cos_diff)


# ------------------------------------------------------------------------------
# 6) μ̂ trajectories with MK-RBF (multi-kernel RBF)
# ------------------------------------------------------------------------------
# The MK path builds a per-layer sigma grid around the median pairwise distance
# and (for μ̂ here) uses uniform weights across sigmas. We scan PCA thresholds
# and keep the one with the best bootstrap std-score.
plt.figure(figsize=(10, 6))
for y_label in abv_labels:
    vals, _ = m.mu_hat_along_layers(
        class_label=y_label,
        n_samples=700,
        image_z=img,
        true_label=true_label,
        kernel="mk_rbf",          # underlying code path implements MK with RBF kernels
        mk_n_scales=3,
        plot_res=False,
        mk_ratio=0.5,
        mk_sigma_center=None,     # per-layer median heuristic
        normalize_each_kernel=True,
        weights=None,             # uniform weights for μ̂ (by design)
        energy_threshold=thr_grid # try multiple PCA thresholds; pick best per layer
    )

    plt.plot(x, vals, marker="o", linewidth=2.8,
             label=f"{y_label} ({np.mean(vals):.2f})",
             color=colors[y_label])
    print(f"MK mu hat for test img {true_label}")
    mk.append(vals)

plt.legend(loc="best", fontsize=22, ncols=1)
plt.tight_layout()
plt.tick_params(axis='both', which='major', labelsize=16)
safe = true_label.replace("/", "__").replace(" ", "_")
plt.savefig(os.path.join(out_dir, f"{safe}__vs_all__mk.pdf"))
plt.close()

# Same separability summary for MK trajectories.
mk_diff = np.abs(mk[1] - mk[0])
mk_cum_diff = np.sum(mk_diff)

# Print both cumulative difference scores for a quick at-a-glance comparison.
print(cos_cum_diff)
print(mk_cum_diff)
